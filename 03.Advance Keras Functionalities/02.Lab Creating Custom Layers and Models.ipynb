{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "442557c0-6268-4386-93c7-5848003600d7",
   "metadata": {},
   "source": [
    "# Creating Custom Layers and Models**\n",
    "\n",
    "##### Learning objectives \n",
    "\n",
    "By the end of this lab, you will: \n",
    "- Create custom layers and integrate them into a Keras model \n",
    "- Compile, train, and evaluate the model \n",
    "\n",
    "##### Prerequisites:\n",
    "- Basic understanding of Python and Keras. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7aa364-e60b-4e0c-8c94-1f50ad4402c1",
   "metadata": {},
   "source": [
    "#### Steps \n",
    "\n",
    "**Step 1: Install and Import libraries**\n",
    "\n",
    "Before you start, import the required libraries: TensorFlow and Keras. Keras is included within TensorFlow as `tensorflow.keras`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03321ca7-01d6-461c-8420-ed3628af3159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.16.2 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (2.16.2)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.2 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow==2.16.2) (2.16.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.14.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.4.0)\n",
      "Requirement already satisfied: packaging in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (4.25.8)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (2.32.4)\n",
      "Requirement already satisfied: setuptools in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (1.73.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.10.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow==2.16.2) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.45.1)\n",
      "Requirement already satisfied: rich in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (14.0.0)\n",
      "Requirement already satisfied: namex in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.1.0)\n",
      "Requirement already satisfied: optree in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (2025.7.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.8.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow==2.16.2) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydot\n",
      "  Obtaining dependency information for pydot from https://files.pythonhosted.org/packages/7e/32/a7125fb28c4261a627f999d5fb4afff25b523800faed2c30979949d6facd/pydot-4.0.1-py3-none-any.whl.metadata\n",
      "  Downloading pydot-4.0.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting graphviz\n",
      "  Obtaining dependency information for graphviz from https://files.pythonhosted.org/packages/91/4c/e0ce1ef95d4000ebc1c11801f9b944fa5910ecc15b5e351865763d8657f8/graphviz-0.21-py3-none-any.whl.metadata\n",
      "  Downloading graphviz-0.21-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: pyparsing>=3.1.0 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from pydot) (3.2.3)\n",
      "Downloading pydot-4.0.1-py3-none-any.whl (37 kB)\n",
      "Downloading graphviz-0.21-py3-none-any.whl (47 kB)\n",
      "   ---------------------------------------- 0.0/47.3 kB ? eta -:--:--\n",
      "   ------------------------- -------------- 30.7/47.3 kB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 47.3/47.3 kB 788.5 kB/s eta 0:00:00\n",
      "Installing collected packages: pydot, graphviz\n",
      "Successfully installed graphviz-0.21 pydot-4.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.16.2\n",
    "!pip install pydot graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65019967-622f-42e3-ac14-3dbfe5246202",
   "metadata": {},
   "source": [
    "#### After installing the libraries, restart the kernel and then run the cells below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13c5f26c-a0a7-4434-abe9-16e4cac5d5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b10ba3-a71d-4c43-a383-2ff14d43b91a",
   "metadata": {},
   "source": [
    "**Step 2: Define a custom layer**\n",
    "\n",
    "Define a custom dense layer with 32 units and ReLU activation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82506cd3-cb83-4caa-be96-9206d5c33a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDenseLayer(Layer):\n",
    "    def __init__(self, units=32):\n",
    "        super(CustomDenseLayer, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.units,),\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "    def call(self, inputs):\n",
    "        return tf.nn.relu(tf.matmul(inputs, self.w) + self.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc729691-f952-4fd6-bd73-2a691fbd1626",
   "metadata": {},
   "source": [
    "**Step 3: Integrate the custom layer into a model**\n",
    "\n",
    "Create a Keras model using the custom layer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2184ae3a-88ef-47cc-8a91-4db766f479b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Softmax\n",
    "\n",
    "model = Sequential([\n",
    "    CustomDenseLayer(128),\n",
    "    CustomDenseLayer(10),\n",
    "    Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082012c8-c193-45ff-9c3e-e479329c7d95",
   "metadata": {},
   "source": [
    "The **Softmax** activation function is used in the output layer for multi-class classification tasks, ensuring the model outputs probabilities that sum up to 1 for each class, which aligns with categorical cross-entropy as the loss function. This adjustment ensures the model is optimized correctly for multi-class classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b01a4a-82a0-42e6-a045-ed3d871edc11",
   "metadata": {},
   "source": [
    "**Step 4: Compile the model**\n",
    "\n",
    "Compile the model with the Adam optimizer and categorical cross-entropy loss. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2b3adb-5269-4cbf-b7d1-4f60dfa8723e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary before building:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ custom_dense_layer              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomDenseLayer</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ custom_dense_layer_1            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomDenseLayer</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ custom_dense_layer              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mCustomDenseLayer\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ custom_dense_layer_1            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mCustomDenseLayer\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ softmax (\u001b[38;5;33mSoftmax\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From b:\\Git hub\\Deep_Learning\\.env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "\n",
      "Model summary after building:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ custom_dense_layer              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomDenseLayer</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ custom_dense_layer_1            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomDenseLayer</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ custom_dense_layer              │ (\u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m2,688\u001b[0m │\n",
       "│ (\u001b[38;5;33mCustomDenseLayer\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ custom_dense_layer_1            │ (\u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "│ (\u001b[38;5;33mCustomDenseLayer\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ softmax (\u001b[38;5;33mSoftmax\u001b[0m)               │ (\u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,978</span> (15.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,978\u001b[0m (15.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,978</span> (15.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,978\u001b[0m (15.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "print(\"Model summary before building:\")\n",
    "model.summary()\n",
    "\n",
    "model.build((1000, 20))\n",
    "print(\"\\nModel summary after building:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ec8b5e-e959-4c90-80f5-af4320e7e9ba",
   "metadata": {},
   "source": [
    "**Step 5: Train the model**\n",
    "\n",
    "Train the model on some example data. For this example, you will generate random data for training. In practice, use a real data set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc7bcac5-d4aa-427a-801c-c1b2fbabb4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.3039  \n",
      "Epoch 2/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3018 \n",
      "Epoch 3/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.2976 \n",
      "Epoch 4/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.2964 \n",
      "Epoch 5/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.2938 \n",
      "Epoch 6/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.2871 \n",
      "Epoch 7/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.2883 \n",
      "Epoch 8/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.2825 \n",
      "Epoch 9/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.2798 \n",
      "Epoch 10/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.2837 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1cff9345050>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "x_train = np.random.random((1000, 20)) \n",
    "y_train = np.random.randint(10, size=(1000, 1)) \n",
    "\n",
    "# Convert labels to categorical one-hot encoding \n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10) \n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a298950-fbd8-4c3f-b927-0b5f4dcc3c40",
   "metadata": {},
   "source": [
    "**Step 6: Evaluate the model**\n",
    "\n",
    "Evaluate the model using test data to see its performance. \n",
    "\n",
    "For this example, you will generate random test data. In practice, use a real data set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0329b78-5585-4bbb-976d-6eb83c9203d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3238 \n",
      "Test loss: 2.319890022277832\n"
     ]
    }
   ],
   "source": [
    "# Generate random test data \n",
    "x_test = np.random.random((200, 20)) \n",
    "y_test = np.random.randint(10, size=(200, 1)) \n",
    "\n",
    "# Convert labels to categorical one-hot encoding \n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10) \n",
    "\n",
    "# Evaluate the model \n",
    "loss = model.evaluate(x_test, y_test) \n",
    "print(f'Test loss: {loss}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0deeb25f-26f8-4e3a-aedb-9c4a9e87bb83",
   "metadata": {},
   "source": [
    "### Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd729da-7ddf-4793-8dea-ec3a6d1c2c21",
   "metadata": {},
   "source": [
    "#### Exercise 1: Visualize Model Architecture\n",
    "\n",
    "**Objective:** Visualize the architecture of the custom Keras model to understand its structure.\n",
    "\n",
    "**Instructions:**\n",
    "1. Use the `plot_model` function from `tensorflow.keras.utils` to visualize the model architecture.\n",
    "2. Save the plot as an image file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf01f92f-bbe4-4d8c-8df3-77c066880869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='model_architecture.png', show_shapes= True, show_layers_names= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943d1249-1ab4-48e0-a0ed-4384230d686d",
   "metadata": {},
   "source": [
    "#### Exercise 2: Add Dropout Layer\n",
    "\n",
    "**Objective:** Enhance the model by adding a Dropout layer to prevent overfitting.\n",
    "\n",
    "**Instructions:**\n",
    "1. Add a Dropout layer between the custom dense layers.\n",
    "2. Recompile the model and observe the impact on training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "633cef8f-09ed-46b3-a2d1-32115ee163fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8.0093   \n",
      "Epoch 2/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6133 \n",
      "Epoch 3/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7149 \n",
      "Epoch 4/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1096 \n",
      "Epoch 5/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3372 \n",
      "Epoch 6/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3187 \n",
      "Epoch 7/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3279 \n",
      "Epoch 8/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3025 \n",
      "Epoch 9/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3316 \n",
      "Epoch 10/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3149 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1cff8930110>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    CustomDenseLayer(64),\n",
    "    Dropout(0.5),\n",
    "    CustomDenseLayer(10)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79985829-5f29-499a-a03c-dd997d4050bd",
   "metadata": {},
   "source": [
    "#### Exercise 3: Adjust the Number of Units in Custom Layer\n",
    "\n",
    "**Objective:** Experiment with different numbers of units in the custom dense layer to observe the impact on performance.\n",
    "\n",
    "**Instructions:**\n",
    "1. Change the number of units in the `CustomDenseLayer` to 128.\n",
    "2. Recompile, train, and evaluate the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae1266d1-f314-4962-b19e-6d5b63418365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.9657   \n",
      "Epoch 2/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.4951 \n",
      "Epoch 3/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.7583 \n",
      "Epoch 4/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.4668 \n",
      "Epoch 5/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.5930 \n",
      "Epoch 6/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.5757 \n",
      "Epoch 7/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.5655 \n",
      "Epoch 8/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.3074 \n",
      "Epoch 9/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.1069 \n",
      "Epoch 10/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.2814 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1cffcf5dcd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomDenseLayer(Layer):\n",
    "    def __init__(self, units=128):\n",
    "        super(CustomDenseLayer, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.units,),\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.nn.relu(tf.matmul(inputs, self.w) + self.b)\n",
    "\n",
    "model = Sequential([\n",
    "    CustomDenseLayer(128),\n",
    "    CustomDenseLayer(10)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcd0726-f997-4f8a-893a-b2d8e256b6d4",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "By completing these exercises, students will:\n",
    "\n",
    "1. Visualize the architecture of their custom Keras model.\n",
    "2. Understand the impact of adding Dropout layers to prevent overfitting.\n",
    "3. Experiment with different configurations of the custom dense layer to observe performance changes.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "prev_pub_hash": "77ffccc5c929015cf9779774debc2074e0d2ffe990bf963198d05886397f6869"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
