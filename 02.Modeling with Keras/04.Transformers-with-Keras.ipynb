{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18d361d0-8fd8-4bf1-ad3f-e0346ee0d42f",
   "metadata": {},
   "source": [
    "# Transformers with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6e35e5-7ff0-460b-bec9-5a56cd6e6ac2",
   "metadata": {},
   "source": [
    "The Keras library to build a transformer using a sequence-to-sequence architecture with self-attention for translation. We will train the model using a sample dataset and then use this model for English to Spanish translation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a6ec8f-f443-4ed0-83c4-89dce58d2df9",
   "metadata": {},
   "source": [
    "# Objectives for this Notebook    \n",
    "* How to use the Keras library to build transformers model\n",
    "* Train the transformer model using a given dataset\n",
    "* Use the trained transformer model to translate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36936894-9d64-49a8-8f38-216ed3d858bf",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "\n",
    "1. <a href=\"#Import-Keras-and-Packages\">Import Keras and Packages</a><br>\n",
    "2. <a href=\"#Step-1:-Data-Preparation\">Step 1: Data Preparation</a><br>\n",
    "3. <a href=\"#Step-2:-Self-Attention-Layer\">Step 2: Self-Attention Layer</a><br>\n",
    "4. <a href=\"#Step-3:-Model-Architecture\">Step 3: Model Architecture</a><br>\n",
    "5. <a href=\"#Step-4:-Training-the-Model\">Step 4: Training the Model</a><br>\n",
    "6. <a href=\"#Step-5:-Plotting-the-training-loss\">Step 5: Plotting the training loss</a><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e09398-3e45-4c55-bff9-a46b72306e9e",
   "metadata": {},
   "source": [
    "## Import Keras and Packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0f0ec8-0273-420c-a8f1-8e8cb4d21cc4",
   "metadata": {},
   "source": [
    "The following required libraries are __not__ pre-installed in the Skills Network Labs environment. __You will need to run the following cell__ to install them:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68e65ffe-c076-4b58-86a5-54d66f8caab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.17.1 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (2.17.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.1 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow==2.17.1) (2.17.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow==2.17.1) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow==2.17.1) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow==2.17.1) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow==2.17.1) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow==2.17.1) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow==2.17.1) (3.14.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow==2.17.1) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow==2.17.1) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow==2.17.1) (3.4.0)\n",
      "Requirement already satisfied: packaging in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow==2.17.1) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow==2.17.1) (4.25.8)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow==2.17.1) (2.32.4)\n",
      "Requirement already satisfied: setuptools in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow==2.17.1) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow==2.17.1) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow==2.17.1) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow==2.17.1) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow==2.17.1) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow==2.17.1) (1.73.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow==2.17.1) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow==2.17.1) (3.10.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow==2.17.1) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorflow-intel==2.17.1->tensorflow==2.17.1) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.1->tensorflow==2.17.1) (0.45.1)\n",
      "Requirement already satisfied: rich in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow==2.17.1) (14.0.0)\n",
      "Requirement already satisfied: namex in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow==2.17.1) (0.1.0)\n",
      "Requirement already satisfied: optree in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow==2.17.1) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.1->tensorflow==2.17.1) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.1->tensorflow==2.17.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.1->tensorflow==2.17.1) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.1->tensorflow==2.17.1) (2025.7.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.1->tensorflow==2.17.1) (3.8.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.1->tensorflow==2.17.1) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.1->tensorflow==2.17.1) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.1->tensorflow==2.17.1) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow==2.17.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow==2.17.1) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.1->tensorflow==2.17.1) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib==3.9.2 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from matplotlib==3.9.2) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from matplotlib==3.9.2) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from matplotlib==3.9.2) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from matplotlib==3.9.2) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from matplotlib==3.9.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from matplotlib==3.9.2) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from matplotlib==3.9.2) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from matplotlib==3.9.2) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from matplotlib==3.9.2) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in b:\\git hub\\deep_learning\\.env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib==3.9.2) (1.17.0)\n",
      "==== All required libraries are installed =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.17.1\n",
    "!pip install matplotlib==3.9.2\n",
    "\n",
    "print(\"==== All required libraries are installed =====\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b6698d-3cbb-4046-beff-2219941d4eef",
   "metadata": {},
   "source": [
    "#### Suppress the tensorflow warning messages\n",
    "We use the following code to  suppress the warning messages due to use of CPU architechture for tensoflow.\n",
    "\n",
    "You may want to **comment out** these lines if you are using the GPU architechture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30ec5512-a446-4e25-8774-1111452084a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb8169c-27d3-43f9-9a2b-1c5dc63d6815",
   "metadata": {},
   "source": [
    "##### To use Keras, you will also need to install a backend framework – such as TensorFlow.\n",
    "\n",
    "If you install TensorFlow 2.16 or above, it will install Keras by default.\n",
    "\n",
    "We are using the CPU version of tensorflow since we are dealing with smaller datasets. \n",
    "You may install the GPU version of tensorflow on your machine to accelarate the processing of larger datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff95da7-40b3-47f6-97d3-e5ccaa2bf057",
   "metadata": {},
   "source": [
    "### Import the necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93d26526-f908-4ae9-aed9-c50def07085f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Layer, Dense, Embedding, LSTM, Dropout\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras import backend as K\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4c50cd-f5dd-45de-96c2-3a452663ee4f",
   "metadata": {},
   "source": [
    "# Step 1: Data Preparation\n",
    "We start by define the sentences and text for translation training\n",
    "Sentence Pairs: Defines a small dataset of English-Spanish sentence pairs.\n",
    "Target Sequences:\n",
    "Prepends \"startseq\" and appends \"endseq\" to each target sentence for the decoder to learn when to start and stop translating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f9987df-4835-40b1-874c-49d58afbcb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample parallel sentences (English -> Spanish)\n",
    "input_texts = [\n",
    "    \"Hello.\", \"How are you?\", \"I am learning machine translation.\", \"What is your name?\", \"I love programming.\"\n",
    "]\n",
    "target_texts = [\n",
    "    \"Hola.\", \"¿Cómo estás?\", \"Estoy aprendiendo traducción automática.\", \"¿Cuál es tu nombre?\", \"Me encanta programar.\"\n",
    "]\n",
    "\n",
    "target_texts = [ \"startseq\" + x + \"endseq\" for x in target_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba970cc5-057d-4472-91da-0581acb3073a",
   "metadata": {},
   "source": [
    "## Next, we convert the text from the sentences to tokens and create a vocabulary\n",
    "Tokenization: Uses Tokenizer to convert words into numerical sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "269bb486-3321-4b6f-836a-47970734768e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "input_tokenizer= Tokenizer()\n",
    "input_tokenizer.fit_on_texts(input_texts)\n",
    "input_sequences= input_tokenizer.texts_to_sequences(input_texts)\n",
    "\n",
    "output_tokenizer= Tokenizer()\n",
    "output_tokenizer.fit_on_texts(target_texts)\n",
    "output_sequences= output_tokenizer.texts_to_sequences(target_texts)\n",
    "\n",
    "input_vocab_size= len(input_tokenizer.word_index) + 1\n",
    "output_vocab_size= len(output_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cc8bd3-03b4-4e0c-85a0-6380416c8dff",
   "metadata": {},
   "source": [
    "### Now pad the corresponding sentences\n",
    "Padding: Ensures all sequences have the same length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9916ada6-5530-483e-abb3-adb4eba04e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding\n",
    "max_input_seq= max([len(seq) for seq in input_sequences])\n",
    "max_output_seq= max([len(seq) for seq in output_sequences])\n",
    "\n",
    "input_sequences= pad_sequences(input_sequences, maxlen= max_input_seq, padding=\"post\")\n",
    "output_sequences= pad_sequences(output_sequences, maxlen= max_output_seq, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fabe671-6387-43ef-a302-d33b5bea8f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the target data for training\n",
    "decoder_input_data= output_sequences[:,:-1]\n",
    "decoder_output_data= output_sequences[:,1:]\n",
    "\n",
    "decoder_output_data= np.array([np.eye(output_vocab_size)[seq] for seq in decoder_output_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47695b1e-ee64-4329-a7ab-8f203c1e753f",
   "metadata": {},
   "source": [
    "# Step 2: Self-Attention Layer\n",
    "Self-attention is a mechanism that allows a model to **focus on relevant parts of the input sequence** while processing each word. This is particularly useful in:\n",
    "1) Machine Translation (e.g., aligning words correctly)\n",
    "2) Text Summarization\n",
    "3) Speech Recognition\n",
    "4) Image Processing (Vision Transformers)\n",
    "In this implementation, self-attention is used for text based sequence-to-sequence modeling.\n",
    "\n",
    "\n",
    "Self-Attention works for a given an input sequence by computing a weighted representation of all words for each position. It does so using three key components:\n",
    "\n",
    "1. Query **(Q)**, Key **(K)**, and Value **(V)** Matrices\n",
    "For each word (token) in a sequence:\n",
    "\n",
    "Query (Q): What this word is looking for.\n",
    "Key (K): What this word represents.\n",
    "Value (V): The actual information in the word.\n",
    "\n",
    "2. Compute **Attention Scores**\n",
    "Next, we **calculate the similarity between each query and key** using dot-product attention:\n",
    "Each word in a sequence attends to every other word based on these scores.\n",
    "\n",
    "3. Apply **Scaling & Softmax**\n",
    "Since dot-product values can be large, we scale them. \n",
    "Next, Applying softmax converts scores into attention weights:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec06747-e423-4c08-8b9e-b5814f8c415d",
   "metadata": {},
   "source": [
    "### Self-Attention class\n",
    "In this implementation of self-attention layer:\n",
    "1. We first initialize the weights in the **build** method, where:\n",
    "    1. **self.Wq**, **self.Wk**, **self.Wv** are the trainable weight matrices.\n",
    "    2. Their **shape is (feature_dim, feature_dim)**, meaning they transform input features into Q, K, and V representations.\n",
    "2. Applying Attention using **call** method. The **call()** method:\n",
    "   1. Computes **Q, K, V** by multiplying inputs (encoder/decoder output) with their respective weight matrices.\n",
    "   2. Computes **dot-product attention scores** using K.batch_dot(q, k, axes=[2, 2]), resulting in a (batch_size, seq_len, seq_len) matrix.\n",
    "   3. **Scales** the scores to avoid large values.\n",
    "   4. Applies **softmax** to normalize the attention scores.\n",
    "   5. **Multiplies attention weights with V** to get the final output.\n",
    "3. The **compute_output_shape** method defines the shape of the output tensor after the layer processes an input.\n",
    "    1. The output shape of the Self-Attention layer **remains the same** as the input shape.\n",
    "    2. The attention mechanism **transforms** the input but does not change its dimensions.4\n",
    "    3. If the attention layer changed the shape, you would modify compute_output_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4287d3f5-3688-487a-99c6-3ff80fccc5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Self-Attention Layer\n",
    "class SelfAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        feature_dim = input_shape[-1]\n",
    "        # Weight matrices for Q, K, V\n",
    "        self.Wq = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='glorot_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wq')\n",
    "        self.Wk = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='glorot_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wk')\n",
    "        self.Wv = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='glorot_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wv')\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Linear projections\n",
    "        q = K.dot(inputs, self.Wq)  # Query\n",
    "        k = K.dot(inputs, self.Wk)  # Key\n",
    "        v = K.dot(inputs, self.Wv)  # Value\n",
    "\n",
    "        # Scaled Dot-Product Attention\n",
    "        scores = K.batch_dot(q, k, axes=[2, 2])  # (batch, seq_len, seq_len)\n",
    "        scores = scores / K.sqrt(K.cast(K.shape(k)[-1], dtype=K.floatx()))  # Scale\n",
    "        attention_weights = K.softmax(scores, axis=-1)  # Normalize\n",
    "\n",
    "        # Weighted sum of values\n",
    "        output = K.batch_dot(attention_weights, v)  # (batch, seq_len, feature_dim)\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c607fc3-20c4-4a95-8c1a-8176907f6321",
   "metadata": {},
   "source": [
    "# Step 3: Model Architecture\n",
    "The model follows an Encoder-Decoder structure:\n",
    "\n",
    "### Encoder:\n",
    "1) Takes input sentences (padded and tokenized).\n",
    "2) Uses an Embedding layer (word representations) + LSTM (to process sequences).\n",
    "    1. The LSTMs are used as the **help process variable-length input sentences** and generate meaningful translations.\n",
    "4) Outputs context vectors (hidden & cell states).\n",
    "\n",
    "### Attention Layer\n",
    "1) Applied to both the encoder and decoder outputs.\n",
    "2) Helps the decoder focus on relevant words during translation.\n",
    "\n",
    "### Decoder\n",
    "1) Receives target sequences (shifted one step ahead).\n",
    "2) Uses an LSTM with encoder states as initial states.\n",
    "3) Applies self-attention for better learning.\n",
    "4) Uses a Dense layer (Softmax) to predict the next word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e98f7b7c-c78c-476a-9dd7-bba63b88da89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],       │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">196,608</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttention</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,112</span> │ self_attention_1… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,096\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,096\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],       │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │    \u001b[38;5;34m196,608\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mSelfAttention\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │      \u001b[38;5;34m4,112\u001b[0m │ self_attention_1… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,536</span> (4.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,536\u001b[0m (4.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,536</span> (4.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,536\u001b[0m (4.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_input_seq,))\n",
    "encoder_embedding = Embedding(input_vocab_size, 256)(encoder_inputs)\n",
    "encoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Attention Mechanism\n",
    "attention_layer = SelfAttention()(encoder_outputs)\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(max_output_seq - 1,))\n",
    "decoder_embedding = Embedding(output_vocab_size, 256)(decoder_inputs)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_attention = SelfAttention()(decoder_outputs)  # Apply attention\n",
    "decoder_dense = Dense(output_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_attention)\n",
    "\n",
    "# Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefd6545-aa2c-41cd-b328-7cbd253f434a",
   "metadata": {},
   "source": [
    "# Step 4: Training the Model\n",
    "Uses categorical_crossentropy as the loss function since output words are one-hot encoded.\n",
    "Trains using Adam optimizer for 100 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c27926c-a3a7-485e-a48d-9ec32089cc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.2500 - loss: 2.7686\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.4000 - loss: 2.7205\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.4000 - loss: 2.6620\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.3500 - loss: 2.5802\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.3500 - loss: 2.4619\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.3500 - loss: 2.2970\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.3500 - loss: 2.1014\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.3500 - loss: 1.9786\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.3500 - loss: 2.0048\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.3500 - loss: 1.9547\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.4000 - loss: 1.8763\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.2500 - loss: 1.8627\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.2500 - loss: 1.8305\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.2500 - loss: 1.7752\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.4000 - loss: 1.7249\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.4000 - loss: 1.6856\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4000 - loss: 1.6534\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.4000 - loss: 1.6240\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.4000 - loss: 1.5924\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.4000 - loss: 1.5529\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.4000 - loss: 1.5022\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.4000 - loss: 1.4433\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.4000 - loss: 1.3843\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4000 - loss: 1.3369\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.4000 - loss: 1.3101\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.3500 - loss: 1.2969\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.3500 - loss: 1.2732\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.4000 - loss: 1.2389\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.4000 - loss: 1.2284\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4000 - loss: 1.2384\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.4000 - loss: 1.2194\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.4000 - loss: 1.1892\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4000 - loss: 1.2045\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.4000 - loss: 1.1973\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.4000 - loss: 1.1769\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.4500 - loss: 1.1743\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.4000 - loss: 1.1649\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.4000 - loss: 1.1618\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.4000 - loss: 1.1516\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.4000 - loss: 1.1407\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4000 - loss: 1.1316\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.4000 - loss: 1.1165\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4500 - loss: 1.1108\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.4000 - loss: 1.0804\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.4000 - loss: 1.0620\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.4500 - loss: 1.0401\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4500 - loss: 1.0060\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4500 - loss: 0.9763\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5000 - loss: 0.9433\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5500 - loss: 0.9013\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.5500 - loss: 0.8655\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6500 - loss: 0.8203\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.6500 - loss: 0.7824\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7000 - loss: 0.7225\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6774\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6256\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.5749\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8500 - loss: 0.5462\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8000 - loss: 0.4991\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8000 - loss: 0.4686\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7500 - loss: 0.5081\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8500 - loss: 0.6876\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7000 - loss: 0.5524\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7000 - loss: 0.5412\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8000 - loss: 0.5262\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6500 - loss: 0.6463\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7000 - loss: 0.5446\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.5375\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.8000 - loss: 0.5027\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.5190\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8500 - loss: 0.4912\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8000 - loss: 0.4835\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7500 - loss: 0.5227\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7000 - loss: 0.4956\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8000 - loss: 0.4420\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8000 - loss: 0.4164\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9500 - loss: 0.3620\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8000 - loss: 0.3738\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8000 - loss: 0.3778\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8000 - loss: 0.4108\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8000 - loss: 0.3658\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8000 - loss: 0.3577\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8000 - loss: 0.3495\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8500 - loss: 0.3108\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9000 - loss: 0.3048\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8500 - loss: 0.3056\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9000 - loss: 0.2873\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9000 - loss: 0.2772\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9000 - loss: 0.2758\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9000 - loss: 0.2787\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9500 - loss: 0.2685\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9000 - loss: 0.2504\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9000 - loss: 0.2383\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9000 - loss: 0.2334\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9000 - loss: 0.2362\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9500 - loss: 0.2370\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9500 - loss: 0.2279\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9500 - loss: 0.2188\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9500 - loss: 0.2126\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9500 - loss: 0.2098\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Train the Model\n",
    "history_glorot_adam = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0d231b-0aa1-419f-94a9-129e25b78127",
   "metadata": {},
   "source": [
    "# Step 5: Plotting the training loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c07b1df-03e8-4f9e-a612-6d8d11c23118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting training loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'])\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0855d65-2545-4dc8-863a-c7368e2239ac",
   "metadata": {},
   "source": [
    "## Practice excercise 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6230c08f-6453-4ad7-a145-5a5fb3d1e5a2",
   "metadata": {},
   "source": [
    "In this practice exercise, let's train the model using \"he_uniform\" initializer instead of \"glorot_uniform\". Then, compare the training loss between model using \"glorot_uniform\" vs \"he_uniform\" initializers by plotting them using matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "360eb9d3-d42d-4fc8-bdf2-f2da26080a3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'max_input_length' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     39\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m input_shape\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m#Encoder\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m encoder_inputs = Input(shape=(\u001b[43mmax_input_length\u001b[49m,))\n\u001b[32m     44\u001b[39m encoder_embedding = Embedding(input_vocab_size, \u001b[32m256\u001b[39m)(encoder_inputs)\n\u001b[32m     45\u001b[39m encoder_lstm = LSTM(\u001b[32m256\u001b[39m, return_sequences=\u001b[38;5;28;01mTrue\u001b[39;00m, return_state=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'max_input_length' is not defined"
     ]
    }
   ],
   "source": [
    "#Define the Self-Attention Layer\n",
    "class SelfAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        feature_dim = input_shape[-1]\n",
    "        # Weight matrices for Q, K, V\n",
    "        self.Wq = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wq')\n",
    "        self.Wk = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wk')\n",
    "        self.Wv = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wv')\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Linear projections\n",
    "        q = K.dot(inputs, self.Wq)  # Query\n",
    "        k = K.dot(inputs, self.Wk)  # Key\n",
    "        v = K.dot(inputs, self.Wv)  # Value\n",
    "\n",
    "        # Scaled Dot-Product Attention\n",
    "        scores = K.batch_dot(q, k, axes=[2, 2])  # (batch, seq_len, seq_len)\n",
    "        scores = scores / K.sqrt(K.cast(K.shape(k)[-1], dtype=K.floatx()))  # Scale\n",
    "        attention_weights = K.softmax(scores, axis=-1)  # Normalize\n",
    "\n",
    "        # Weighted sum of values\n",
    "        output = K.batch_dot(attention_weights, v)  # (batch, seq_len, feature_dim)\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    \n",
    "#Encoder\n",
    "encoder_inputs = Input(shape=(max_input_length,))\n",
    "encoder_embedding = Embedding(input_vocab_size, 256)(encoder_inputs)\n",
    "encoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "#Attention Mechanism\n",
    "attention_layer = SelfAttention()(encoder_outputs)\n",
    "\n",
    "#Decoder\n",
    "decoder_inputs = Input(shape=(max_output_length - 1,))\n",
    "decoder_embedding = Embedding(output_vocab_size, 256)(decoder_inputs)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_attention = SelfAttention()(decoder_outputs)  # Apply attention\n",
    "decoder_dense = Dense(output_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_attention)\n",
    "\n",
    "#Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#Step 6: Train the Model\n",
    "history_he = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)\n",
    "\n",
    "#Plotting training losses for glorot_uniform and he_uniform inititalizers\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'], label=\"glorot_uniform\", color='red')\n",
    "plt.plot(history_he.history['loss'], label=\"he_uniform\", color='blue')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ced5c66-b585-4b26-910f-5dc6c9088cb7",
   "metadata": {},
   "source": [
    "## Practice excercise 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ff7782-3ec9-4696-9e75-359f5828ffe0",
   "metadata": {},
   "source": [
    "In this practice exercise, try to use adaptive gradient optimizer instead of adam. Then, plot and compare the results between adam and adaptive gradient optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d166af3-696c-439f-8ef1-80198b85a1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.1174\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.1172\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.1171\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.1170\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.1169\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.1168\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.1167\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.1166\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.1165\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.1164\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.1163\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.1162\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.1161\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.1161\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.1160\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.1159\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.1158\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.1157\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.1156\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.1156\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.1155\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.1154\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.1153\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.1153\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.1152\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.1151\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.1150\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.1150\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.1149\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.1148\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.1148\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.1147\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.1146\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.1146\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.1145\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.1144\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.1144\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.1143\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.1143\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.1142\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.1141\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.1141\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.1140\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.1140\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.1139\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.1138\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.1138\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.1137\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.1137\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.1136\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.1136\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.1135\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.1134\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.1134\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.1133\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.1133\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.1132\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.1132\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.1131\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.1131\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.1130\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.1130\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.1129\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.1129\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.1128\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.1128\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.1127\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.1127\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.1126\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.1126\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.1125\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.1125\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.1124\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.1124\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.1123\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.1123\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.1122\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.1122\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.1122\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.1121\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.1121\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.1120\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.1120\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.1119\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.1119\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.1118\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.1118\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.1118\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.1117\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.1117\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.1116\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.1116\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.1115\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.1115\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.1115\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.1114\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.1114\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.1113\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.1113\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.1112\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adagrad', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#Step 6: Train the Model\n",
    "history_adagrad = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)\n",
    "\n",
    "#Plotting training losses for glorot_uniform and he_uniform inititalizers\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'], label=\"adam\", color='red')\n",
    "plt.plot(history_adagrad.history['loss'], label=\"adagrad\", color='blue')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "prev_pub_hash": "89fa9a3db18ab099ea8b241e966f29a2f658cfbd6a742128f10daea40c67df82"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
